{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data",
   "id": "cbf9374a988e21f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T23:05:58.239375Z",
     "start_time": "2025-11-25T23:05:58.231766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "id": "3605493328eee29b",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T23:05:59.787698Z",
     "start_time": "2025-11-25T23:05:59.710920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = openml.datasets.get_dataset(40498)\n",
    "X, y, _, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "y = y.astype(float)\n",
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "data"
   ],
   "id": "64396ae7e8e1aa56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       V1    V2    V3    V4     V5    V6     V7       V8    V9   V10   V11  \\\n",
       "0     7.0  0.27  0.36  20.7  0.045  45.0  170.0  1.00100  3.00  0.45   8.8   \n",
       "1     6.3  0.30  0.34   1.6  0.049  14.0  132.0  0.99400  3.30  0.49   9.5   \n",
       "2     8.1  0.28  0.40   6.9  0.050  30.0   97.0  0.99510  3.26  0.44  10.1   \n",
       "3     7.2  0.23  0.32   8.5  0.058  47.0  186.0  0.99560  3.19  0.40   9.9   \n",
       "4     7.2  0.23  0.32   8.5  0.058  47.0  186.0  0.99560  3.19  0.40   9.9   \n",
       "...   ...   ...   ...   ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "4893  6.2  0.21  0.29   1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "4894  6.6  0.32  0.36   8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "4895  6.5  0.24  0.19   1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "4896  5.5  0.29  0.30   1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "4897  6.0  0.21  0.38   0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      Class  \n",
       "0       4.0  \n",
       "1       4.0  \n",
       "2       4.0  \n",
       "3       4.0  \n",
       "4       4.0  \n",
       "...     ...  \n",
       "4893    4.0  \n",
       "4894    3.0  \n",
       "4895    4.0  \n",
       "4896    5.0  \n",
       "4897    4.0  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train test split",
   "id": "c7de3a01dbc3b1c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T23:06:02.192164Z",
     "start_time": "2025-11-25T23:06:02.178862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train"
   ],
   "id": "c913addb3e4a663a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       V1    V2    V3     V4     V5    V6     V7       V8    V9   V10   V11\n",
       "4665  7.3  0.17  0.36   8.20  0.028  44.0  111.0  0.99272  3.14  0.41  12.4\n",
       "1943  6.3  0.25  0.44  11.60  0.041  48.0  195.0  0.99680  3.18  0.52   9.5\n",
       "3399  5.6  0.32  0.33   7.40  0.037  25.0   95.0  0.99268  3.25  0.49  11.1\n",
       "843   6.9  0.19  0.35   1.70  0.036  33.0  101.0  0.99315  3.21  0.54  10.8\n",
       "2580  7.7  0.30  0.26  18.95  0.053  36.0  174.0  0.99976  3.20  0.50  10.4\n",
       "...   ...   ...   ...    ...    ...   ...    ...      ...   ...   ...   ...\n",
       "4426  6.2  0.21  0.52   6.50  0.047  28.0  123.0  0.99418  3.22  0.49   9.9\n",
       "466   7.0  0.14  0.32   9.00  0.039  54.0  141.0  0.99560  3.22  0.43   9.4\n",
       "3092  7.6  0.27  0.52   3.20  0.043  28.0  152.0  0.99129  3.02  0.53  11.4\n",
       "3772  6.3  0.24  0.29  13.70  0.035  53.0  134.0  0.99567  3.17  0.38  10.6\n",
       "860   8.1  0.27  0.35   1.70  0.030  38.0  103.0  0.99255  3.22  0.63  10.4\n",
       "\n",
       "[3918 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4665</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.028</td>\n",
       "      <td>44.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99272</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.41</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.44</td>\n",
       "      <td>11.60</td>\n",
       "      <td>0.041</td>\n",
       "      <td>48.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.037</td>\n",
       "      <td>25.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.99268</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.036</td>\n",
       "      <td>33.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99315</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>18.95</td>\n",
       "      <td>0.053</td>\n",
       "      <td>36.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.99976</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.047</td>\n",
       "      <td>28.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.99418</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.039</td>\n",
       "      <td>54.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.043</td>\n",
       "      <td>28.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.99129</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.035</td>\n",
       "      <td>53.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.99567</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.030</td>\n",
       "      <td>38.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.99255</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3918 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Metric and train/optimize/judge function",
   "id": "c7e09556ccca7399"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T23:31:31.710439Z",
     "start_time": "2025-11-25T23:31:31.690536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "def metric(y_hat, y_true,features_shape):\n",
    "    n,p = features_shape\n",
    "    r2 = r2_score(y_true, y_hat)\n",
    "    socres = {\n",
    "        \"MAE\": mean_absolute_error(y_true, y_hat),\n",
    "        \"MSE\": mean_squared_error(y_true, y_hat),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_hat)),\n",
    "        \"R2\": r2,\n",
    "        \"Adjusted R2\":  1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    }\n",
    "\n",
    "    df_score = pd.DataFrame(socres.items(), columns=[\"Metric\",\"Value\"])\n",
    "\n",
    "    return df_score\n",
    "\n",
    "def optimize_train_and_judge(model_class, objective_fn, trails=100):\n",
    "    global x_train, y_train, x_test, y_test, names\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "    start = time.time()\n",
    "    study.optimize(objective_fn, n_trials=trails, show_progress_bar=True)\n",
    "    stop = time.time()\n",
    "\n",
    "    best_params = study.best_params.copy()\n",
    "\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('feature_selection', SelectKBest()), ('model', model_class())])\n",
    "\n",
    "    pipe.set_params(**best_params)\n",
    "\n",
    "    pipe.fit(x_train, y_train)\n",
    "    y_hat_train = pipe.predict(x_train)\n",
    "    y_hat_test = pipe.predict(x_test)\n",
    "\n",
    "    print(f\"Time {stop - start}\\n\")\n",
    "    df_test = metric(y_hat_test, y_test,x_test.shape)\n",
    "\n",
    "    return pipe, df_test\n"
   ],
   "id": "8f54f9e898cec827",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forest",
   "id": "b8d89a5ffca6be98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T23:39:45.747824Z",
     "start_time": "2025-11-25T23:35:09.396333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def objective_RF(trial):\n",
    "    # selector\n",
    "    k = trial.suggest_int('feature_selection__k', 1, 10)\n",
    "\n",
    "    #model\n",
    "    n_estimators = trial.suggest_int('model__n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('model__max_depth', 3, 20)\n",
    "    min_samples_split = trial.suggest_int('model__min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('model__min_samples_leaf', 1, 10)\n",
    "\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('feature_selection', SelectKBest(score_func=f_regression, k=k)), ('model', RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf))])\n",
    "    pipe.fit(x_train, y_train)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(pipe, x_train, y_train, cv=cv, scoring= 'neg_mean_squared_error').mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "rf_pipe, rf_metric = optimize_train_and_judge(RandomForestRegressor, objective_RF, trails=30)\n",
    "\n",
    "rf_metric"
   ],
   "id": "5a959b88dd1c404d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-26 00:35:09,399] A new study created in memory with name: no-name-40603431-ec85-42da-9e1d-4f8d7c7ce3fc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7437fb2232e46c1becaae267f50303d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-26 00:35:17,031] Trial 0 finished with value: -0.47104281187827457 and parameters: {'feature_selection__k': 8, 'model__n_estimators': 172, 'model__max_depth': 14, 'model__min_samples_split': 15, 'model__min_samples_leaf': 5}. Best is trial 0 with value: -0.47104281187827457.\n",
      "[I 2025-11-26 00:35:19,037] Trial 1 finished with value: -0.5440227082085165 and parameters: {'feature_selection__k': 4, 'model__n_estimators': 137, 'model__max_depth': 6, 'model__min_samples_split': 2, 'model__min_samples_leaf': 3}. Best is trial 0 with value: -0.47104281187827457.\n",
      "[I 2025-11-26 00:35:22,030] Trial 2 finished with value: -0.53193697742857 and parameters: {'feature_selection__k': 4, 'model__n_estimators': 159, 'model__max_depth': 10, 'model__min_samples_split': 6, 'model__min_samples_leaf': 10}. Best is trial 0 with value: -0.47104281187827457.\n",
      "[I 2025-11-26 00:35:25,838] Trial 3 finished with value: -0.565479648290595 and parameters: {'feature_selection__k': 3, 'model__n_estimators': 201, 'model__max_depth': 18, 'model__min_samples_split': 19, 'model__min_samples_leaf': 1}. Best is trial 0 with value: -0.47104281187827457.\n",
      "[I 2025-11-26 00:35:26,758] Trial 4 finished with value: -0.57829804685883 and parameters: {'feature_selection__k': 3, 'model__n_estimators': 55, 'model__max_depth': 12, 'model__min_samples_split': 2, 'model__min_samples_leaf': 9}. Best is trial 0 with value: -0.47104281187827457.\n",
      "[I 2025-11-26 00:35:27,390] Trial 5 finished with value: -0.6339815222520174 and parameters: {'feature_selection__k': 1, 'model__n_estimators': 105, 'model__max_depth': 7, 'model__min_samples_split': 18, 'model__min_samples_leaf': 6}. Best is trial 0 with value: -0.47104281187827457.\n",
      "[I 2025-11-26 00:35:38,578] Trial 6 finished with value: -0.4661208142754522 and parameters: {'feature_selection__k': 7, 'model__n_estimators': 252, 'model__max_depth': 18, 'model__min_samples_split': 12, 'model__min_samples_leaf': 1}. Best is trial 6 with value: -0.4661208142754522.\n",
      "[I 2025-11-26 00:35:52,304] Trial 7 finished with value: -0.4506022060234024 and parameters: {'feature_selection__k': 10, 'model__n_estimators': 289, 'model__max_depth': 18, 'model__min_samples_split': 14, 'model__min_samples_leaf': 8}. Best is trial 7 with value: -0.4506022060234024.\n",
      "[I 2025-11-26 00:35:54,882] Trial 8 finished with value: -0.5283227384263427 and parameters: {'feature_selection__k': 4, 'model__n_estimators': 133, 'model__max_depth': 10, 'model__min_samples_split': 5, 'model__min_samples_leaf': 8}. Best is trial 7 with value: -0.4506022060234024.\n",
      "[I 2025-11-26 00:36:02,235] Trial 9 finished with value: -0.46287397335985847 and parameters: {'feature_selection__k': 10, 'model__n_estimators': 170, 'model__max_depth': 9, 'model__min_samples_split': 10, 'model__min_samples_leaf': 1}. Best is trial 7 with value: -0.4506022060234024.\n",
      "[I 2025-11-26 00:36:16,465] Trial 10 finished with value: -0.44688251613756724 and parameters: {'feature_selection__k': 10, 'model__n_estimators': 293, 'model__max_depth': 20, 'model__min_samples_split': 13, 'model__min_samples_leaf': 7}. Best is trial 10 with value: -0.44688251613756724.\n",
      "[I 2025-11-26 00:36:31,873] Trial 11 finished with value: -0.4466450633117104 and parameters: {'feature_selection__k': 10, 'model__n_estimators': 298, 'model__max_depth': 16, 'model__min_samples_split': 13, 'model__min_samples_leaf': 7}. Best is trial 11 with value: -0.4466450633117104.\n",
      "[I 2025-11-26 00:36:45,916] Trial 12 finished with value: -0.4672509114080675 and parameters: {'feature_selection__k': 8, 'model__n_estimators': 300, 'model__max_depth': 20, 'model__min_samples_split': 10, 'model__min_samples_leaf': 6}. Best is trial 11 with value: -0.4466450633117104.\n",
      "[I 2025-11-26 00:36:57,854] Trial 13 finished with value: -0.4701826069854727 and parameters: {'feature_selection__k': 9, 'model__n_estimators': 254, 'model__max_depth': 15, 'model__min_samples_split': 15, 'model__min_samples_leaf': 7}. Best is trial 11 with value: -0.4466450633117104.\n",
      "[I 2025-11-26 00:37:00,774] Trial 14 finished with value: -0.5710021476525448 and parameters: {'feature_selection__k': 6, 'model__n_estimators': 226, 'model__max_depth': 3, 'model__min_samples_split': 8, 'model__min_samples_leaf': 4}. Best is trial 11 with value: -0.4466450633117104.\n",
      "[I 2025-11-26 00:37:14,549] Trial 15 finished with value: -0.44677562490146777 and parameters: {'feature_selection__k': 10, 'model__n_estimators': 266, 'model__max_depth': 15, 'model__min_samples_split': 13, 'model__min_samples_leaf': 7}. Best is trial 11 with value: -0.4466450633117104.\n",
      "[I 2025-11-26 00:37:24,468] Trial 16 finished with value: -0.4859959653084073 and parameters: {'feature_selection__k': 8, 'model__n_estimators': 255, 'model__max_depth': 15, 'model__min_samples_split': 17, 'model__min_samples_leaf': 10}. Best is trial 11 with value: -0.4466450633117104.\n",
      "[I 2025-11-26 00:37:31,674] Trial 17 finished with value: -0.48638848640895116 and parameters: {'feature_selection__k': 6, 'model__n_estimators': 214, 'model__max_depth': 13, 'model__min_samples_split': 16, 'model__min_samples_leaf': 4}. Best is trial 11 with value: -0.4466450633117104.\n",
      "[I 2025-11-26 00:37:43,840] Trial 18 finished with value: -0.4755483704067977 and parameters: {'feature_selection__k': 9, 'model__n_estimators': 268, 'model__max_depth': 16, 'model__min_samples_split': 11, 'model__min_samples_leaf': 8}. Best is trial 11 with value: -0.4466450633117104.\n",
      "[I 2025-11-26 00:37:54,565] Trial 19 finished with value: -0.46861353626894087 and parameters: {'feature_selection__k': 9, 'model__n_estimators': 226, 'model__max_depth': 17, 'model__min_samples_split': 8, 'model__min_samples_leaf': 7}. Best is trial 11 with value: -0.4466450633117104.\n",
      "[I 2025-11-26 00:38:03,339] Trial 20 finished with value: -0.4952679367503106 and parameters: {'feature_selection__k': 7, 'model__n_estimators': 273, 'model__max_depth': 12, 'model__min_samples_split': 20, 'model__min_samples_leaf': 9}. Best is trial 11 with value: -0.4466450633117104.\n",
      "[I 2025-11-26 00:38:17,969] Trial 21 finished with value: -0.44729269029786484 and parameters: {'feature_selection__k': 10, 'model__n_estimators': 300, 'model__max_depth': 20, 'model__min_samples_split': 13, 'model__min_samples_leaf': 7}. Best is trial 11 with value: -0.4466450633117104.\n",
      "[I 2025-11-26 00:38:32,364] Trial 22 finished with value: -0.4398952050312637 and parameters: {'feature_selection__k': 10, 'model__n_estimators': 276, 'model__max_depth': 20, 'model__min_samples_split': 13, 'model__min_samples_leaf': 5}. Best is trial 22 with value: -0.4398952050312637.\n",
      "[I 2025-11-26 00:38:43,843] Trial 23 finished with value: -0.4627508967852621 and parameters: {'feature_selection__k': 9, 'model__n_estimators': 238, 'model__max_depth': 16, 'model__min_samples_split': 12, 'model__min_samples_leaf': 5}. Best is trial 22 with value: -0.4398952050312637.\n",
      "[I 2025-11-26 00:38:54,852] Trial 24 finished with value: -0.4323724082456003 and parameters: {'feature_selection__k': 10, 'model__n_estimators': 198, 'model__max_depth': 14, 'model__min_samples_split': 9, 'model__min_samples_leaf': 3}. Best is trial 24 with value: -0.4323724082456003.\n",
      "[I 2025-11-26 00:39:03,168] Trial 25 finished with value: -0.46673283667599597 and parameters: {'feature_selection__k': 7, 'model__n_estimators': 196, 'model__max_depth': 19, 'model__min_samples_split': 9, 'model__min_samples_leaf': 3}. Best is trial 24 with value: -0.4323724082456003.\n",
      "[I 2025-11-26 00:39:06,202] Trial 26 finished with value: -0.45805859710762586 and parameters: {'feature_selection__k': 9, 'model__n_estimators': 57, 'model__max_depth': 13, 'model__min_samples_split': 6, 'model__min_samples_leaf': 3}. Best is trial 24 with value: -0.4323724082456003.\n",
      "[I 2025-11-26 00:39:15,812] Trial 27 finished with value: -0.4557722511407499 and parameters: {'feature_selection__k': 8, 'model__n_estimators': 194, 'model__max_depth': 17, 'model__min_samples_split': 11, 'model__min_samples_leaf': 2}. Best is trial 24 with value: -0.4323724082456003.\n",
      "[I 2025-11-26 00:39:31,348] Trial 28 finished with value: -0.4284962648394345 and parameters: {'feature_selection__k': 10, 'model__n_estimators': 278, 'model__max_depth': 17, 'model__min_samples_split': 7, 'model__min_samples_leaf': 4}. Best is trial 28 with value: -0.4284962648394345.\n",
      "[I 2025-11-26 00:39:42,540] Trial 29 finished with value: -0.45609891904330907 and parameters: {'feature_selection__k': 8, 'model__n_estimators': 238, 'model__max_depth': 19, 'model__min_samples_split': 5, 'model__min_samples_leaf': 4}. Best is trial 28 with value: -0.4284962648394345.\n",
      "Time 273.1424717903137\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        Metric     Value\n",
       "0          MAE  0.464948\n",
       "1          MSE  0.383752\n",
       "2         RMSE  0.619477\n",
       "3           R2  0.504500\n",
       "4  Adjusted R2  0.498869"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.464948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSE</td>\n",
       "      <td>0.383752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.619477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.504500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adjusted R2</td>\n",
       "      <td>0.498869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# xgboost",
   "id": "5f8c071684a2f80b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T23:39:56.856661Z",
     "start_time": "2025-11-25T23:39:46.548188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "def objective_RF(trial):\n",
    "    # selector\n",
    "    k = trial.suggest_int('feature_selection__k', 1, 10)\n",
    "\n",
    "    #model\n",
    "    learning_rate = trial.suggest_float('model__learning_rate', 0.01, 0.3)\n",
    "    subsample = trial.suggest_float('model__subsample', 0.6, 1.0)\n",
    "\n",
    "\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('feature_selection', SelectKBest(score_func=f_regression, k=k)), ('model', XGBRegressor(learning_rate=learning_rate, subsample=subsample))])\n",
    "    pipe.fit(x_train, y_train)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(pipe, x_train, y_train, cv=cv, scoring= 'neg_mean_squared_error').mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "xgb_pipe, xgb_metric = optimize_train_and_judge(XGBRegressor, objective_RF, trails=30)\n",
    "xgb_metric"
   ],
   "id": "2f4d77e2525b1501",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-26 00:39:46,550] A new study created in memory with name: no-name-5792b14c-057b-4b42-bf58-b740892b9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d9536f36b444b1eb4030eb58503dd12"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-26 00:39:47,071] Trial 0 finished with value: -0.4510240264707496 and parameters: {'feature_selection__k': 10, 'model__learning_rate': 0.2330803125231316, 'model__subsample': 0.7935871880196892}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:47,446] Trial 1 finished with value: -0.4740916343330376 and parameters: {'feature_selection__k': 9, 'model__learning_rate': 0.12855001032251084, 'model__subsample': 0.7176560839100661}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:47,789] Trial 2 finished with value: -0.5304467002421532 and parameters: {'feature_selection__k': 7, 'model__learning_rate': 0.2971612955532658, 'model__subsample': 0.6691961243756869}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:48,148] Trial 3 finished with value: -0.47120860280269017 and parameters: {'feature_selection__k': 8, 'model__learning_rate': 0.1645468414055689, 'model__subsample': 0.8418124247205072}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:48,505] Trial 4 finished with value: -0.47835127659717447 and parameters: {'feature_selection__k': 8, 'model__learning_rate': 0.07237500230805614, 'model__subsample': 0.8940111133636419}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:48,751] Trial 5 finished with value: -0.6016479769341915 and parameters: {'feature_selection__k': 2, 'model__learning_rate': 0.056806496095509196, 'model__subsample': 0.7944352218355973}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:49,006] Trial 6 finished with value: -0.5805133486538294 and parameters: {'feature_selection__k': 3, 'model__learning_rate': 0.1549551443205983, 'model__subsample': 0.9481855266458475}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:49,338] Trial 7 finished with value: -0.49319272512902546 and parameters: {'feature_selection__k': 7, 'model__learning_rate': 0.1274237787606444, 'model__subsample': 0.6081389583515279}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:49,669] Trial 8 finished with value: -0.4842736769302597 and parameters: {'feature_selection__k': 8, 'model__learning_rate': 0.10815308393041415, 'model__subsample': 0.6137419307131928}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:49,902] Trial 9 finished with value: -0.5886576095279461 and parameters: {'feature_selection__k': 3, 'model__learning_rate': 0.20316491056430713, 'model__subsample': 0.9513356781205569}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:50,254] Trial 10 finished with value: -0.45598848263701164 and parameters: {'feature_selection__k': 10, 'model__learning_rate': 0.26029693809679094, 'model__subsample': 0.7663677015676719}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:50,602] Trial 11 finished with value: -0.4662800793685067 and parameters: {'feature_selection__k': 10, 'model__learning_rate': 0.2574947257511472, 'model__subsample': 0.7673816797605677}. Best is trial 0 with value: -0.4510240264707496.\n",
      "[I 2025-11-26 00:39:50,951] Trial 12 finished with value: -0.4477702545100099 and parameters: {'feature_selection__k': 10, 'model__learning_rate': 0.2367649119318631, 'model__subsample': 0.7348513973603922}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:51,238] Trial 13 finished with value: -0.4969266923286937 and parameters: {'feature_selection__k': 6, 'model__learning_rate': 0.20984298987032798, 'model__subsample': 0.8498510443219837}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:51,512] Trial 14 finished with value: -0.5137916215508017 and parameters: {'feature_selection__k': 5, 'model__learning_rate': 0.20905422203475071, 'model__subsample': 0.7037737996060127}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:51,863] Trial 15 finished with value: -0.46424825994834584 and parameters: {'feature_selection__k': 10, 'model__learning_rate': 0.26132985237473844, 'model__subsample': 0.727285746863958}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:52,138] Trial 16 finished with value: -0.5087328651103195 and parameters: {'feature_selection__k': 5, 'model__learning_rate': 0.2302895067975566, 'model__subsample': 0.8420909151210836}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:52,519] Trial 17 finished with value: -0.51268006029843 and parameters: {'feature_selection__k': 9, 'model__learning_rate': 0.29779455899824525, 'model__subsample': 0.662869426203586}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:52,735] Trial 18 finished with value: -0.6347101832192552 and parameters: {'feature_selection__k': 1, 'model__learning_rate': 0.0205968292561452, 'model__subsample': 0.8810361380430118}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:53,104] Trial 19 finished with value: -0.4738663721793171 and parameters: {'feature_selection__k': 9, 'model__learning_rate': 0.1846153539629566, 'model__subsample': 0.7995247750145918}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:53,423] Trial 20 finished with value: -0.5220807673241397 and parameters: {'feature_selection__k': 6, 'model__learning_rate': 0.2393015271849534, 'model__subsample': 0.7517856530319467}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:53,811] Trial 21 finished with value: -0.46236870279822373 and parameters: {'feature_selection__k': 10, 'model__learning_rate': 0.27314076206256493, 'model__subsample': 0.7688086135251486}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:54,200] Trial 22 finished with value: -0.4531620075095213 and parameters: {'feature_selection__k': 10, 'model__learning_rate': 0.233906265745076, 'model__subsample': 0.6880207101260509}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:54,573] Trial 23 finished with value: -0.48520911133556943 and parameters: {'feature_selection__k': 9, 'model__learning_rate': 0.2272604786923985, 'model__subsample': 0.6809519155990819}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:54,959] Trial 24 finished with value: -0.45825194901526495 and parameters: {'feature_selection__k': 10, 'model__learning_rate': 0.18656431417160507, 'model__subsample': 0.6376627378694941}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:55,319] Trial 25 finished with value: -0.4974441816052659 and parameters: {'feature_selection__k': 8, 'model__learning_rate': 0.2375825276149724, 'model__subsample': 0.7300675875161533}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:55,693] Trial 26 finished with value: -0.4945062994980777 and parameters: {'feature_selection__k': 9, 'model__learning_rate': 0.2811974107062536, 'model__subsample': 0.6951299043675441}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:56,018] Trial 27 finished with value: -0.4858776625886067 and parameters: {'feature_selection__k': 7, 'model__learning_rate': 0.16291338228850946, 'model__subsample': 0.991133212339861}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:56,406] Trial 28 finished with value: -0.4662758835284819 and parameters: {'feature_selection__k': 10, 'model__learning_rate': 0.25154228027873327, 'model__subsample': 0.6436915610458981}. Best is trial 12 with value: -0.4477702545100099.\n",
      "[I 2025-11-26 00:39:56,778] Trial 29 finished with value: -0.4727387414553187 and parameters: {'feature_selection__k': 9, 'model__learning_rate': 0.18808728737007216, 'model__subsample': 0.7380657139277541}. Best is trial 12 with value: -0.4477702545100099.\n",
      "Time 10.229079008102417\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        Metric     Value\n",
       "0          MAE  0.449331\n",
       "1          MSE  0.377999\n",
       "2         RMSE  0.614817\n",
       "3           R2  0.511927\n",
       "4  Adjusted R2  0.506381"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.449331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSE</td>\n",
       "      <td>0.377999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.614817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.511927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adjusted R2</td>\n",
       "      <td>0.506381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Wilcoxon test",
   "id": "cbbab8e312049a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T23:40:28.925883Z",
     "start_time": "2025-11-25T23:40:28.726235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from statsmodels.stats.nonparametric import rank_compare_2indep\n",
    "knn_probs = rf_pipe.predict(x_test)\n",
    "logistic_probs = xgb_pipe.predict(x_test)\n",
    "\n",
    "rank_compare_2indep(knn_probs, logistic_probs).summary()"
   ],
   "id": "c9cff0a248206c3a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ],
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Probability sample 1 is stochastically larger</caption>\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prob(x1>x2) c0</th> <td>    0.5084</td> <td>    0.013</td> <td>    0.640</td> <td> 0.522</td> <td>    0.483</td> <td>    0.534</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": "\\begin{center}\n\\begin{tabular}{lcccccc}\n\\toprule\n                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{prob(x1$>$x2) c0} &       0.5084  &        0.013     &     0.640  &         0.522        &        0.483    &        0.534     \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{Probability sample 1 is stochastically larger}\n\\end{center}"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
